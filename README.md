# ğŸ“š Five Rocks - Bot de SumarizaÃ§Ã£o de Processos Judiciais

Sistema de IA especializado em resumir documentos jurÃ­dicos brasileiros (petiÃ§Ãµes, sentenÃ§as, acÃ³rdÃ£os, despachos) usando OpenAI GPT. Desenvolvido para advogados que precisam processar grandes volumes de documentos processuais de forma eficiente e precisa.

## ğŸ¯ CaracterÃ­sticas Principais

- âœ… **Resumos JurÃ­dicos Especializados**: Prompts especÃ­ficos para cada tipo de documento (petiÃ§Ã£o inicial, sentenÃ§a, acÃ³rdÃ£o, despacho)
- âœ… **Estrutura Padronizada**: Resumos em formato JSON estruturado com metadados jurÃ­dicos
- âœ… **ExtraÃ§Ã£o AutomÃ¡tica de Metadados**: Identifica nÃºmero do processo, tribunal, partes, tipo de aÃ§Ã£o
- âœ… **ValidaÃ§Ã£o de Qualidade**: ValidaÃ§Ã£o automÃ¡tica dos resumos gerados
- âœ… **Tratamento Robusto de Erros**: Detecta e trata PDFs protegidos, corrompidos, DOCX com problemas
- âœ… **OtimizaÃ§Ã£o de Custos**: Usa `gpt-4o-mini` e otimiza tokens para reduzir custos
- âœ… **Processamento Paralelo**: Processa mÃºltiplos documentos simultaneamente com controle de concorrÃªncia
- âœ… **Suporte a Documentos Grandes**: Processa documentos de 2000+ pÃ¡ginas com estratÃ©gia hierÃ¡rquica

## ğŸ“‹ Ãndice

- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [Uso BÃ¡sico](#-uso-bÃ¡sico)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Arquitetura](#-arquitetura)
- [Formato de Resumo](#-formato-de-resumo)
- [Tratamento de Erros](#-tratamento-de-erros)
- [OtimizaÃ§Ãµes](#-otimizaÃ§Ãµes)
- [Troubleshooting](#-troubleshooting)
- [DocumentaÃ§Ã£o TÃ©cnica](#-documentaÃ§Ã£o-tÃ©cnica)

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.10 ou superior
- pip (gerenciador de pacotes Python)
- Chave de API da OpenAI

### Passo a Passo

1. **Clone o repositÃ³rio** (ou navegue atÃ© o diretÃ³rio do projeto):
```bash
cd five-rocks
```

2. **Crie um ambiente virtual** (recomendado):
```bash
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows
```

3. **Instale as dependÃªncias**:
```bash
pip install -r requirements.txt
```

4. **Configure as variÃ¡veis de ambiente**:
```bash
cp .env.example .env  # Se houver arquivo de exemplo
# Ou crie um arquivo .env manualmente
```

5. **Adicione sua chave da OpenAI no arquivo `.env`**:
```env
OPENAI_API_KEY=sua_chave_aqui
```

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com:

```env
OPENAI_API_KEY=sua_chave_da_openai_aqui
```

### ConfiguraÃ§Ã£o do Modelo

Por padrÃ£o, o sistema usa `gpt-4o-mini` para otimizar custos. VocÃª pode alterar o modelo no cÃ³digo:

```python
from core.openai_summarizer import OpenAISummarizer

summarizer = OpenAISummarizer(
    model="gpt-4o-mini",  # ou "gpt-4o", "gpt-3.5-turbo", etc.
    max_retries=3,
    max_parallel_chunks=5
)
```

### DiretÃ³rio de Dados

Por padrÃ£o, o sistema procura documentos na pasta `data/`. VocÃª pode alterar isso em `config.py`:

```python
DATA_DIR = "data"  # Altere para o caminho desejado
```

## ğŸ“– Uso BÃ¡sico

### Uso Simples

1. **Coloque seus documentos** na pasta `data/`:
   - Arquivos PDF (`.pdf`)
   - Arquivos Word (`.docx`)

2. **Execute o script principal**:
```bash
python3 main.py
```

3. **Aguarde o processamento**. O sistema irÃ¡:
   - Encontrar todos os arquivos PDF e DOCX
   - Processar cada um em paralelo (mÃ¡ximo 3 simultÃ¢neos)
   - Gerar resumos estruturados em JSON
   - Exibir resultados no console

### Exemplo de SaÃ­da

```
============================================================
 ğŸ“š BOT DE SUMARIZAÃ‡ÃƒO DE PROCESSOS (ASYNC)
============================================================

ğŸ” Encontrados: 8 arquivo(s) para processar (4 PDF(s), 4 DOCX(s))
Processando: 0012197-59.2022.5.15.0135_1grau.pdf
Processando: 0011037-65.2018.5.15.0126_1grau.pdf
...
  [1/8] âœ“ 0012197-59.2022.5.15.0135 Leitura Processo.docx
  [2/8] âœ“ 0010466-09.2022.5.15.0012 Leitura Processo.docx
...

============================================================
 RESULTADOS - TODOS OS ARQUIVOS
============================================================

ğŸ“Š Processados: 8 | Sucesso: 8 | Erros: 0 | Taxa: 100.0% | Tempo: 125000ms

ğŸ“„ Resumos gerados:
----------------------------------------

â–¶ 0012197-59.2022.5.15.0135 Leitura Processo.docx
  Palavras: 15234 | Tempo: 21792ms
  {
    "resumo_executivo": "...",
    "numero_processo": "0012197-59.2022.5.15.0135",
    ...
  }
```

### Uso ProgramÃ¡tico

```python
import asyncio
from adapters import PdfAdapter, DocxAdapter
from core.openai_summarizer import OpenAISummarizer
from services.document_service import DocumentService

async def process_document():
    # Inicializa componentes
    summarizer = OpenAISummarizer()
    adapter = PdfAdapter()  # ou DocxAdapter()
    
    # Cria serviÃ§o
    service = DocumentService(
        adapter=adapter,
        summarizer=summarizer
    )
    
    # Processa arquivo
    result = await service.process_file("data/processo.pdf")
    
    if result.is_success:
        print(f"Resumo: {result.summary}")
        print(f"Palavras: {result.word_count}")
    else:
        print(f"Erro: {result.error_message}")

# Executa
asyncio.run(process_document())
```

## ğŸ“ Estrutura do Projeto

```
five-rocks/
â”œâ”€â”€ adapters/              # Adaptadores para leitura de documentos
â”‚   â”œâ”€â”€ base_adapter.py    # Interface base
â”‚   â”œâ”€â”€ pdf_adapter.py    # Leitor de PDFs
â”‚   â””â”€â”€ docx_adapter.py   # Leitor de DOCX
â”‚
â”œâ”€â”€ core/                  # NÃºcleo do sistema
â”‚   â”œâ”€â”€ base_summarizer.py      # Interface do sumarizador
â”‚   â””â”€â”€ openai_summarizer.py    # ImplementaÃ§Ã£o OpenAI
â”‚
â”œâ”€â”€ services/              # ServiÃ§os de negÃ³cio
â”‚   â””â”€â”€ document_service.py     # ServiÃ§o principal de processamento
â”‚
â”œâ”€â”€ utils/                 # UtilitÃ¡rios
â”‚   â”œâ”€â”€ chunck_util.py          # DivisÃ£o de texto em chunks
â”‚   â”œâ”€â”€ legal_metadata_extractor.py  # ExtraÃ§Ã£o de metadados jurÃ­dicos
â”‚   â”œâ”€â”€ legal_prompt_builder.py      # Construtor de prompts jurÃ­dicos
â”‚   â”œâ”€â”€ resume_validator.py          # Validador de resumos
â”‚   â””â”€â”€ file_utils.py               # UtilitÃ¡rios de arquivo
â”‚
â”œâ”€â”€ custom_types/          # Tipos customizados
â”‚   â”œâ”€â”€ document_result.py      # Resultado do processamento
â”‚   â””â”€â”€ batch_result.py         # Resultado de lote
â”‚
â”œâ”€â”€ enums/                 # EnumeraÃ§Ãµes
â”‚   â””â”€â”€ processing_status_enum.py
â”‚
â”œâ”€â”€ data/                  # DiretÃ³rio de documentos (adicione seus PDFs/DOCX aqui)
â”‚
â”œâ”€â”€ main.py                # Script principal
â”œâ”€â”€ config.py              # ConfiguraÃ§Ãµes
â”œâ”€â”€ requirements.txt        # DependÃªncias
â””â”€â”€ README.md              # Este arquivo
```

## ğŸ—ï¸ Arquitetura

### Fluxo de Processamento

```
1. Leitura do Documento
   â”œâ”€â”€ PDF â†’ PdfAdapter
   â””â”€â”€ DOCX â†’ DocxAdapter
   
2. ValidaÃ§Ã£o do Texto
   â”œâ”€â”€ Tamanho mÃ­nimo
   â””â”€â”€ ConteÃºdo vÃ¡lido
   
3. ExtraÃ§Ã£o de Metadados
   â”œâ”€â”€ NÃºmero do processo
   â”œâ”€â”€ Tribunal/Comarca
   â”œâ”€â”€ Partes
   â”œâ”€â”€ Tipo de aÃ§Ã£o
   â””â”€â”€ Tipo de documento
   
4. ConstruÃ§Ã£o do Prompt
   â”œâ”€â”€ Prompt base jurÃ­dico
   â”œâ”€â”€ Prompt especÃ­fico por tipo
   â””â”€â”€ ValidaÃ§Ã£o de metadados
   
5. OtimizaÃ§Ã£o do Texto
   â”œâ”€â”€ Remove espaÃ§os duplos
   â””â”€â”€ Remove quebras desnecessÃ¡rias
   
6. DivisÃ£o em Chunks (se necessÃ¡rio)
   â”œâ”€â”€ Chunks de 3000 palavras
   â””â”€â”€ Preserva contexto jurÃ­dico
   
7. Processamento Paralelo
   â”œâ”€â”€ AtÃ© 5 chunks simultÃ¢neos
   â””â”€â”€ Retry com backoff exponencial
   
8. CombinaÃ§Ã£o de Resumos
   â”œâ”€â”€ HierÃ¡rquico se necessÃ¡rio
   â””â”€â”€ Resumo final estruturado
   
9. ValidaÃ§Ã£o
   â”œâ”€â”€ Formato JSON
   â”œâ”€â”€ Campos obrigatÃ³rios
   â””â”€â”€ Qualidade mÃ­nima
   
10. Resultado Final
    â””â”€â”€ JSON estruturado com metadados
```

### Componentes Principais

#### `OpenAISummarizer`
- Gerencia comunicaÃ§Ã£o com API OpenAI
- Implementa estratÃ©gia hierÃ¡rquica para documentos grandes
- Processa chunks em paralelo
- Valida resumos gerados

#### `DocumentService`
- Orquestra o processamento completo
- Gerencia cache (em memÃ³ria)
- Trata erros e validaÃ§Ãµes
- Retorna resultados estruturados

#### `LegalMetadataExtractor`
- Extrai metadados jurÃ­dicos usando regex
- Identifica padrÃµes CNJ
- Detecta tribunais, partes, tipos de aÃ§Ã£o

#### `LegalPromptBuilder`
- ConstrÃ³i prompts especializados
- Adapta prompt ao tipo de documento
- Inclui instruÃ§Ãµes anti-alucinaÃ§Ã£o

#### `ResumeValidator`
- Valida formato JSON
- Verifica campos obrigatÃ³rios
- Detecta informaÃ§Ãµes vagas ou inventadas

## ğŸ“„ Formato de Resumo

Os resumos sÃ£o retornados em formato JSON estruturado:

```json
{
  "resumo_executivo": "Resumo geral em 2-3 parÃ¡grafos com os pontos principais do documento...",
  "numero_processo": "0012197-59.2022.5.15.0135",
  "tribunal": "TJSP",
  "partes": {
    "autor": "JoÃ£o Silva",
    "reu": "Empresa XYZ Ltda",
    "outras_partes": []
  },
  "tipo_acao": "aÃ§Ã£o de cobranÃ§a",
  "tipo_documento": "sentenÃ§a",
  "fatos_relevantes": [
    "Fato 1 descrito no documento",
    "Fato 2 descrito no documento"
  ],
  "fundamentacao": "FundamentaÃ§Ã£o jurÃ­dica resumida...",
  "decisao": "Julgamento procedente em parte...",
  "pedidos": [
    "Pedido 1",
    "Pedido 2"
  ],
  "observacoes": "ObservaÃ§Ãµes relevantes se houver"
}
```

### Campos por Tipo de Documento

#### PetiÃ§Ã£o Inicial
- `partes` (autor, rÃ©u)
- `tipo_acao`
- `fatos_relevantes`
- `fundamentacao`
- `pedidos`

#### SentenÃ§a
- `relatorio` (resumo dos fatos)
- `fundamentacao`
- `decisao` (dispositivo - procedente/improcedente)
- `valor_condenacao` (se houver)

#### AcÃ³rdÃ£o
- `relatorio`
- `votos` (resumo dos votos)
- `fundamentacao`
- `decisao`
- `reforma` (se houve reforma)

#### Despacho
- `materia_decidida`
- `fundamentacao`
- `decisao` (deferido/indeferido)
- `prazo` (se houver)

## âš ï¸ Tratamento de Erros

O sistema trata diversos tipos de erros:

### PDFs
- âœ… **Protegido por senha**: Detecta e informa claramente
- âœ… **Corrompido**: Identifica e trata graciosamente
- âœ… **Apenas imagens**: Detecta quando nÃ£o hÃ¡ texto extraÃ­vel
- âœ… **Qualidade de extraÃ§Ã£o**: Valida se extraiu texto suficiente

### DOCX
- âœ… **Protegido**: Detecta arquivos protegidos
- âœ… **Corrompido**: Trata corrupÃ§Ã£o de arquivo
- âœ… **Tabelas**: Extrai texto de tabelas (importante em processos)
- âœ… **Headers/Footers**: Extrai informaÃ§Ãµes de cabeÃ§alhos e rodapÃ©s

### Texto ExtraÃ­do
- âœ… **Muito curto**: Valida tamanho mÃ­nimo (10 palavras)
- âœ… **Apenas espaÃ§os**: Detecta textos invÃ¡lidos
- âœ… **Qualidade**: Valida conteÃºdo real

### API OpenAI
- âœ… **Rate Limits**: Retry com backoff exponencial
- âœ… **Timeouts**: Tratamento de timeouts
- âœ… **Erros de API**: Mensagens de erro claras

## ğŸš€ OtimizaÃ§Ãµes

### OtimizaÃ§Ã£o de Tokens

1. **Limpeza de Texto**: Remove espaÃ§os duplos, quebras desnecessÃ¡rias
2. **Chunks Maiores**: 3000 palavras por chunk (reduz chamadas)
3. **Modelo Eficiente**: `gpt-4o-mini` para custos baixos
4. **Processamento Paralelo**: AtÃ© 5 chunks simultÃ¢neos

### Performance

1. **Processamento Paralelo**: AtÃ© 3 arquivos simultaneamente
2. **Cache em MemÃ³ria**: Evita reprocessamento
3. **EstratÃ©gia HierÃ¡rquica**: Para documentos muito grandes
4. **ValidaÃ§Ã£o PrÃ©via**: Evita processar textos invÃ¡lidos

### Economia de Custos

- **ReduÃ§Ã£o de ~80%** no nÃºmero de chamadas (chunks maiores)
- **ReduÃ§Ã£o de ~10-15%** em tokens (otimizaÃ§Ã£o de texto)
- **Modelo barato**: `gpt-4o-mini` vs modelos mais caros
- **Total estimado**: ReduÃ§Ã£o de **60-70%** nos custos

## ğŸ”§ Troubleshooting

### Erro: "API key da OpenAI nÃ£o encontrada"

**SoluÃ§Ã£o**: Certifique-se de ter criado o arquivo `.env` com:
```env
OPENAI_API_KEY=sua_chave_aqui
```

### Erro: "PDF protegido por senha"

**Causa**: O PDF estÃ¡ protegido e nÃ£o pode ser lido sem senha.

**SoluÃ§Ã£o**: 
- Remova a proteÃ§Ã£o do PDF antes de processar
- Ou use uma versÃ£o sem proteÃ§Ã£o

### Erro: "Texto extraÃ­do muito curto"

**Causa**: O documento pode estar:
- Corrompido
- Contendo apenas imagens (sem OCR)
- Vazio

**SoluÃ§Ã£o**:
- Verifique se o documento abre corretamente
- Se for PDF escaneado, use OCR antes
- Verifique se o documento nÃ£o estÃ¡ vazio

### Erro: "Resumo nÃ£o estÃ¡ em formato JSON vÃ¡lido"

**Causa**: A IA pode ter retornado texto em vez de JSON.

**SoluÃ§Ã£o**:
- O sistema tenta corrigir automaticamente
- Se persistir, verifique os logs para mais detalhes
- Considere usar um modelo mais recente (gpt-4o)

### Processamento muito lento

**PossÃ­veis causas**:
- Muitos arquivos grandes
- Rate limits da API
- ConexÃ£o lenta

**SoluÃ§Ãµes**:
- Reduza `MAX_PARALLEL_FILES` em `main.py`
- Processe em lotes menores
- Verifique sua conexÃ£o com a API

### MemÃ³ria insuficiente

**Causa**: Documentos muito grandes carregados em memÃ³ria.

**SoluÃ§Ã£o**:
- Processe documentos menores primeiro
- Considere aumentar memÃ³ria disponÃ­vel
- Processe um arquivo por vez (ajuste `MAX_PARALLEL_FILES = 1`)

## ğŸ“š DocumentaÃ§Ã£o TÃ©cnica

### Documentos Adicionais

- **[ANALISE_CRITICA.md](ANALISE_CRITICA.md)**: AnÃ¡lise completa dos problemas identificados
- **[CORRECOES_IMPLEMENTADAS.md](CORRECOES_IMPLEMENTADAS.md)**: DocumentaÃ§Ã£o das correÃ§Ãµes implementadas

### API Reference

#### `OpenAISummarizer`

```python
summarizer = OpenAISummarizer(
    model: str = "gpt-4o-mini",
    api_key: Optional[str] = None,
    max_retries: int = 3,
    max_parallel_chunks: int = 5,
    validate_resume: bool = True
)

# MÃ©todo principal
summary: str = await summarizer.summarize(text: str, prompt: Optional[str] = None)
```

#### `DocumentService`

```python
service = DocumentService(
    summarizer: BaseSummarizer,
    adapter: Optional[BaseAdapter] = None,
    enable_cache: bool = True
)

# Processar um arquivo
result: DocumentResult = await service.process_file(file_path: str)

# Processar lote
batch: BatchResult = await service.process_batch(
    file_paths: List[str],
    on_progress: Optional[Callable] = None
)
```

#### `LegalMetadataExtractor`

```python
extractor = LegalMetadataExtractor()
metadata: LegalMetadata = extractor.extract(text: str)
```

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto Ã© de uso interno. Todos os direitos reservados.

## ğŸ‘¥ Autores

- Desenvolvido para uso em escritÃ³rios de advocacia
- Especializado em processamento de documentos jurÃ­dicos brasileiros

## ğŸ™ Agradecimentos

- OpenAI pela API GPT
- Comunidade Python pelos pacotes utilizados
- Advogados que testaram e forneceram feedback

---

**âš ï¸ Importante**: Este sistema Ã© uma ferramenta de apoio. Sempre revise os resumos gerados antes de usar em processos reais. A IA pode cometer erros ou omitir informaÃ§Ãµes importantes.

**ğŸ“§ Suporte**: Para problemas ou dÃºvidas, consulte a documentaÃ§Ã£o tÃ©cnica ou abra uma issue.
